{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitmyrootcondad860efe0ffde43f19424cf00c4ac03a3",
   "display_name": "Python 3.7.4 64-bit ('my_root': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Clyde\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\Clyde\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\Clyde\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nDownloading Dataset ...\nDataset Downloaded\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import pipelines_FEngineering as BaseLine\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import preprocessingNLP as PNLP\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA, NMF, TruncatedSVD\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "\"\"\"\n",
    "loading test and training data: IMDB Reviews\n",
    "\"\"\"\n",
    "print(\"Downloading Dataset ...\")\n",
    "IMDB_train = load_files('C:/Users/Clyde/Downloads/aclImdb_v1/aclImdb/train/',\n",
    "                        categories=(\"pos\", \"neg\"), encoding='utf-8')\n",
    "IMDB_test = load_files('C:/Users/Clyde/Downloads/aclImdb_v1/aclImdb/test/',\n",
    "                        categories=(\"pos\", \"neg\"), encoding='utf-8')\n",
    "\n",
    "print(\"Dataset Downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "PREPROCESSING ...\nPREPROCESSING DONE!\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "preprocessing\n",
    "\"\"\"\n",
    "print(\"PREPROCESSING ...\")\n",
    "IMDB_train.data = PNLP.customNLP(IMDB_train.data)\n",
    "\n",
    "IMDB_test.data = PNLP.customNLP(IMDB_test.data)\n",
    "\n",
    "IMDB_train.data, IMDB_train.target = PNLP.removeEmptyInstances(IMDB_train.data, IMDB_train.target)\n",
    "\n",
    "print(\"PREPROCESSING DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oscar test"
   ]
  }
 ]
}