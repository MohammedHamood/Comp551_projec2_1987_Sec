{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitmyrootcondad860efe0ffde43f19424cf00c4ac03a3",
   "display_name": "Python 3.7.4 64-bit ('my_root': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Clyde\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\Clyde\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\Clyde\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import pipelines_FEngineering as BaseLine\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import preprocessingNLP as PNLP\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA, NMF,TruncatedSVD\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "loading test and training data: 20newsdataset\n",
    "\"\"\"\n",
    "train_data = fetch_20newsgroups(subset='train',shuffle=True, random_state=42,remove=['headers', 'footers', 'quotes'])\n",
    "test_data = fetch_20newsgroups(subset='test',shuffle=True, random_state=42,remove=['headers', 'footers', 'quotes'])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "preprocessing\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "train_data.data=PNLP.customNLP(train_data.data)\n",
    "\n",
    "test_data.data=PNLP.customNLP(test_data.data)\n",
    "\n",
    "train_data.data,train_data.target=PNLP.removeEmptyInstances(train_data.data,train_data.target)\n",
    "\n",
    "\"\"\"\n",
    "logistic regression \n",
    "\"\"\"\n",
    "parameters = {\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (40000,50000),\n",
    "    #'vect__ngram_range': ((1, 1), (1, 2),(1, 3)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    #'clf__solver': ('lbfgs'),\n",
    "    #'clf__penalty': ('l2','none'),\n",
    "    # 'clf__max_iter': (100,200,300,1000,2000,3000),\n",
    "    # 'clf__C': (100, 50,10, 5, 2,1,.8,.5,.1,.01),\n",
    "}\n",
    "\n",
    "\n",
    "LR_base=BaseLine.Pipeline_FeatureEngineering(train_data.data,train_data.target,\n",
    "                                             parameters=parameters,CV=10,\n",
    "                                             reductionMethod=TruncatedSVD(n_components=100),\n",
    "                                             reductionType=3,model=LogisticRegression(C=5, max_iter=300, penalty='None'))\n",
    "LR_base_pridect=LR_base.predict(test_data.data)\n",
    "\n",
    "print(LR_base.best_estimator_)\n",
    "# Training accuracy\n",
    "print(pd.DataFrame.from_dict(LR_base.cv_results_))\n",
    "print(\"Best score\", LR_base.best_score_)\n",
    "\n",
    "# Test accuracy\n",
    "print(classification_report(test_data.target, LR_base_pridect))\n",
    "print(\"Test accuracy: \", np.mean(LR_base_pridect == test_data.target))\n",
    "\n"
   ]
  }
 ]
}